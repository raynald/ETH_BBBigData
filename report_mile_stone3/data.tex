\section{Data model}
    In this milestone, we use the full GHCN-D\cite{GHCN-D} dataset, which provides weather information from 1763 to 2014. 
    We use Amazon Web Services to run our program, boto\cite{boto} is a Python interface to it. We upload all the data to a bucket in S3\cite{S3}. Since a single file can exceed $1$GB, we divide the data into chunks of size of $50$M.
    The 1763 dataset is only $25$KB, so that we have to identify all the missing values, later when creating feature, replacing them with specific ones.
\begin{table}[htbp]
    \centering
    \caption{Table of datasize in selected years}
    \begin{tabular}{|l|l|l|l|l|l|l|}
        \hline
        Year & 1763 & 1813 & 1863 & 1913 & 1963 & 2013 \\ 
        \hline
        Size & 25k &  78k & 874k & 289M & 953M & 1G \\ 
        \hline 
    \end{tabular}
\end{table}
